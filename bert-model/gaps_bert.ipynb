{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoun\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('data/all-csu-codes.csv', 'r') as c_data:\n",
    "#     csv_reader = csv.reader(c_data) \n",
    "#     courses_data = list(csv_reader)\n",
    "    \n",
    "# courses_df = pd.DataFrame(columns=['Courses', 'Skills'])\n",
    "\n",
    "# for idx in range(0, len(courses_data)):\n",
    "#     skill_list = courses_data[idx][1:-1]\n",
    "#     skill_list = [skill.title() for skill in skill_list]\n",
    "#     skill_list = [re.sub(r'\\b(vs|Vs)\\b', 'VS', skill) for skill in skill_list]\n",
    "\n",
    "#     row = pd.DataFrame({'Courses': courses_data[idx][0], 'Skills':[skill_list]})\n",
    "#     courses_df = pd.concat([courses_df, row], ignore_index=True)\n",
    "\n",
    "# courses_df.to_csv('data/courses_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/descriptions.txt', 'r') as j_data:\n",
    "#     csv_reader = csv.reader(j_data, delimiter='|')\n",
    "#     jobs_data = list(csv_reader)\n",
    "\n",
    "# jobs_df = pd.DataFrame(columns=['Job_Title', 'Job_Description', 'Required_Skills'])\n",
    "                    \n",
    "# for row in jobs_data:\n",
    "#     if len(row) == 3:\n",
    "#         job_title = row[0].strip().strip('\"') \n",
    "\n",
    "#         job_description = row[1].strip().strip('\"')\n",
    "#         job_description = re.sub(r'\\bDESCRIPTION\\b', '', job_description)\n",
    "    \n",
    "#         skills = row[2].strip().strip('\"')\n",
    "#         skill_list = [skill.strip().strip('\"') for skill in skills.split(',')]\n",
    "#         cap_skill_list = [skill.title() for skill in skill_list]\n",
    "#         cleaned_skills = [re.sub(r'\\s?\\(.*?\\)', '', skill) for skill in cap_skill_list]\n",
    "\n",
    "#         row = pd.DataFrame({'Job_Title': job_title, 'Job_Description': job_description, 'Required_Skills': [skill_list]})\n",
    "#         jobs_df = pd.concat([jobs_df, row], ignore_index=True)\n",
    "            \n",
    "# jobs_df.to_csv('data/jobs_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_acquired_skills(courses_df):\n",
    "    all_acquired_skills = set() \n",
    "    \n",
    "    for skills in courses_df['Skills']:\n",
    "        all_acquired_skills.update(skills)\n",
    "\n",
    "    return all_acquired_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_class_comparison(jobs_df, courses_df, all_acquired_skills):\n",
    "    training_data = []\n",
    "    course_entries = list(zip(courses_df[\"Courses\"], courses_df[\"Skills\"]))\n",
    "\n",
    "    for _, job in jobs_df.iterrows():\n",
    "        job_text = f\"Job Title: {job['Job_Title']}\\n Job Description: {job['Job_Description']}\"\n",
    "        job_skills = set(job[\"Required_Skills\"])\n",
    "        missing_skills = job_skills - all_acquired_skills\n",
    "        num_missing = float(len(missing_skills))\n",
    "        num_job_skills = float(len(job_skills))\n",
    "        \n",
    "        course_info = \"COURSES TAKEN:\\n\"\n",
    "        for course, skills in course_entries:\n",
    "            course_info += f\"\\tCOURSE: {course}\\n\\t\\t{course} SKILLS: {', '.join(skills)}\\n\"\n",
    "\n",
    "        query_text = \"What skills am I lacking for the following job position, given the classes I have taken?\\n\\n\" + job_text\n",
    "        query_text += \"\\n\\n\" + course_info\n",
    "        if len(missing_skills) == 0:\n",
    "            acquired_skills = {', '.join(job['Required_Skills'])}\n",
    "            training_data.append({\n",
    "                'query': query_text,\n",
    "                'answer': f\"You qualify as an applicant for the job position, {job['Job_Title']}.\\ Your courses provided all listed required skills: {acquired_skills}\",\n",
    "                'label': 1.0\n",
    "            })\n",
    "        elif num_missing == num_job_skills:\n",
    "            answer = \", \".join(list(missing_skills))\n",
    "            training_data.append({\n",
    "                'query': query_text,\n",
    "                'answer': (f\"You are missing the following skills required by the postion: \" + answer),\n",
    "                'label': 0.0\n",
    "            })\n",
    "        else:\n",
    "            answer = \", \".join(list(missing_skills))\n",
    "            training_data.append({\n",
    "                'query': query_text,\n",
    "                'answer': (f\"You are missing the following skills required by the postion: \" + answer),\n",
    "                'label': (1.0 - (num_missing/num_job_skills))\n",
    "            })\n",
    "        \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_individual_course(jobs_df, courses_df, neg_per_pos=1):\n",
    "    training_data = []\n",
    "     \n",
    "    for _, job in jobs_df.iterrows():\n",
    "        job_text = f\"Job Title: {job['Job_Title']}\\n Job Description: {job['Job_Description']}\"\n",
    "        job_skills = set(job['Required_Skills']) \n",
    "        num_job_skills = float(len(job_skills))\n",
    "        \n",
    "        for _, course in courses_df.iterrows():\n",
    "            missing_skills = list(job_skills - set(course[\"Skills\"]))\n",
    "            num_missing = float(len(missing_skills))\n",
    "            course_info = f\"COURSE TAKEN: {course['Courses']}\\n {course['Courses']} SKILLS: {', '.join(course['Skills'])}\"\n",
    "\n",
    "        query_text = \"What skills am I lacking for the following job position, given the classes I have taken?\\n\\n\" + job_text\n",
    "        query_text += \"\\n\\n\" + course_info\n",
    "        if len(missing_skills) == 0:\n",
    "            acquired_skills = {', '.join(job['Required_Skills'])}\n",
    "            training_data.append({\n",
    "                'query': query_text,\n",
    "                'answer': f\"You qualify as an applicant for the job position, {job['Job_Title']}.\\ Your courses provided all listed required skills: {acquired_skills}\",\n",
    "                'label': 1.0\n",
    "            })\n",
    "        elif num_missing == num_job_skills:\n",
    "            answer = \", \".join(list(missing_skills))\n",
    "            training_data.append({\n",
    "                'query': query_text,\n",
    "                'answer': (f\"You are missing all of the following skills required by the postion: \" + answer),\n",
    "                'label': 0.0\n",
    "            })\n",
    "        else:\n",
    "            answer = \", \".join(list(missing_skills))\n",
    "            training_data.append({\n",
    "                'query': query_text,\n",
    "                'answer': (f\"You are missing the following skills required by the postion: \" + answer),\n",
    "                'label': (1.0 - (num_missing/num_job_skills))\n",
    "            })\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schedule_data(jobs_df, schedules):\n",
    "    training_data = []\n",
    "\n",
    "    for _, job in jobs_df.iterrows():\n",
    "        job_text = f\"Job Title: {job['Job_Title']}\\n Job Description: {job['Job_Description']}\"\n",
    "        job_skills = set(job[\"Required_Skills\"])\n",
    "        num_job_skills = float(len(job_skills))\n",
    "\n",
    "        for sched in schedules:\n",
    "            course_entries = list(zip(sched[\"Courses\"], sched[\"Skills\"]))\n",
    "            sched_skills = set([item for sublist in sched[\"Skills\"].tolist() for item in sublist])\n",
    "            missing_skills = list(job_skills - sched_skills)\n",
    "            num_missing = float(len(missing_skills))\n",
    "            \n",
    "            course_info = \"COURSES TAKEN:\\n\"\n",
    "            for course, skills in course_entries:\n",
    "                course_info += f\"\\tCOURSE: {course}\\n\\t\\t{course} SKILLS: {', '.join(skills)}\\n\"\n",
    "\n",
    "            query_text = \"What skills am I lacking for the following job position, given the classes I have taken?\\n\\n\" + job_text\n",
    "            query_text += \"\\n\\n\" + course_info\n",
    "            if len(missing_skills) == 0:\n",
    "                acquired_skills = {', '.join(job['Required_Skills'])}\n",
    "                training_data.append({\n",
    "                    'query': query_text,\n",
    "                    'answer': f\"You qualify as an applicant for the job position, {job['Job_Title']}.\\ Your courses provided all listed required skills: {acquired_skills}\",\n",
    "                    'label': 1.0\n",
    "                })\n",
    "            elif num_missing == num_job_skills:\n",
    "                answer = \", \".join(list(missing_skills))\n",
    "                training_data.append({\n",
    "                    'query': query_text,\n",
    "                    'answer': (f\"You are missing all of the following skills required by the postion: \" + answer),\n",
    "                    'label': 0.0\n",
    "                })\n",
    "            else:\n",
    "                answer = \", \".join(list(missing_skills))\n",
    "                training_data.append({\n",
    "                    'query': query_text,\n",
    "                    'answer': (f\"You are missing the following skills required by the postion: \" + answer),\n",
    "                    'label': (1.0 - (num_missing/num_job_skills))\n",
    "                })\n",
    "\n",
    "    return training_data\n",
    "\n",
    "\n",
    "def get_courseloads(jobs_df, courses_df, number_of_schedules=20):\n",
    "    core_classes = ['CS150', 'CS164', 'CS152', 'CS162', 'CS201', 'CS165', 'CS220', \n",
    "                    'CS270', 'CS250', 'CS314', 'CS370', 'CS320', 'CS214']\n",
    "    \n",
    "    elective_courses_df = courses_df[~courses_df['Courses'].isin(core_classes)]\n",
    "\n",
    "    schedules_df = []\n",
    "    used_schedules = set()\n",
    "\n",
    "    while len(schedules_df) < number_of_schedules:\n",
    "        l_4_courses = elective_courses_df[elective_courses_df['Courses'].str.startswith('CS4')]\n",
    "        l_3_4_courses = elective_courses_df[elective_courses_df['Courses'].str.startswith('CS3') | elective_courses_df['Courses'].str.startswith('CS4')]\n",
    "        other_courses = elective_courses_df[~elective_courses_df['Courses'].str.startswith('CS3') & ~elective_courses_df['Courses'].str.startswith('CS4')]\n",
    "\n",
    "        l_4_sample = random.sample(l_4_courses['Courses'].tolist(), 2)\n",
    "\n",
    "        l_3_4_filtered = l_3_4_courses[~l_3_4_courses['Courses'].isin(l_4_sample)]\n",
    "        l_3_4_sample = random.sample(l_3_4_filtered['Courses'].tolist(), 2)\n",
    "\n",
    "        all_sampled_courses = l_4_sample + l_3_4_sample\n",
    "        other_courses_filtered = other_courses[~other_courses['Courses'].isin(all_sampled_courses)]\n",
    "        other_sample = random.sample(other_courses_filtered['Courses'].tolist(), 1)\n",
    "\n",
    "        sched_courses = core_classes + l_4_sample + l_3_4_sample + other_sample\n",
    "        sched_df = courses_df[courses_df['Courses'].isin(sched_courses)].copy()\n",
    "\n",
    "        sched_tuple = tuple(sorted(sched_df['Courses'].tolist()))\n",
    "        if sched_tuple not in used_schedules:\n",
    "            schedules_df.append(sched_df)\n",
    "            used_schedules.add(sched_tuple)\n",
    "\n",
    "    training_data = create_schedule_data(jobs_df, schedules_df)\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(jobs_df, courses_df, all_acquired_skills):\n",
    "    training_data = all_class_comparison(jobs_df, courses_df, all_acquired_skills)\n",
    "    print(f\"All: {training_data[-1]}\\n\")\n",
    "\n",
    "    training_data = training_data + compare_individual_course(jobs_df, courses_df)\n",
    "    print(f\"Individual: {training_data[-1]}\\n\")\n",
    "    \n",
    "    training_data = training_data + get_courseloads(jobs_df, courses_df)\n",
    "    print(f\"Course load: {training_data[-1]}\\n\")\n",
    "\n",
    "    return training_data\n",
    "\n",
    "# all_acquired_skills = get_all_acquired_skills(courses_df)\n",
    "# training_data = create_training_data(jobs_df, courses_df, all_acquired_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_data[0])\n",
    "# td_df = pd.DataFrame(training_data, columns=['query', 'answer', 'label'])\n",
    "# print(td_df.shape)\n",
    "\n",
    "# td_df.to_csv('data/bert_training_data.csv', index=False)\n",
    "\n",
    "# del td_df, training_data, jobs_df, courses_df\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query', 'answer', 'label']\n",
      "(1739, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query</td>\n",
       "      <td>answer</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.19354838709677424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.0714285714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.33333333333333337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.15000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.13157894736842102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.1578947368421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.1578947368421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.13157894736842102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>What skills am I lacking for the following job...</td>\n",
       "      <td>You are missing the following skills required ...</td>\n",
       "      <td>0.13157894736842102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1739 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0                                                 query   \n",
       "1     What skills am I lacking for the following job...   \n",
       "2     What skills am I lacking for the following job...   \n",
       "3     What skills am I lacking for the following job...   \n",
       "4     What skills am I lacking for the following job...   \n",
       "...                                                 ...   \n",
       "1734  What skills am I lacking for the following job...   \n",
       "1735  What skills am I lacking for the following job...   \n",
       "1736  What skills am I lacking for the following job...   \n",
       "1737  What skills am I lacking for the following job...   \n",
       "1738  What skills am I lacking for the following job...   \n",
       "\n",
       "                                                 answer                label  \n",
       "0                                                answer                label  \n",
       "1     You are missing the following skills required ...  0.19354838709677424  \n",
       "2     You are missing the following skills required ...   0.0714285714285714  \n",
       "3     You are missing the following skills required ...  0.33333333333333337  \n",
       "4     You are missing the following skills required ...  0.15000000000000002  \n",
       "...                                                 ...                  ...  \n",
       "1734  You are missing the following skills required ...  0.13157894736842102  \n",
       "1735  You are missing the following skills required ...   0.1578947368421053  \n",
       "1736  You are missing the following skills required ...   0.1578947368421053  \n",
       "1737  You are missing the following skills required ...  0.13157894736842102  \n",
       "1738  You are missing the following skills required ...  0.13157894736842102  \n",
       "\n",
       "[1739 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('data/bert_training_data.csv', 'r') as t_data:\n",
    "    csv_reader = csv.reader(t_data) \n",
    "    training_data = list(csv_reader)\n",
    "\n",
    "print(training_data[0])\n",
    "td_df = pd.DataFrame(training_data, columns=['query', 'answer', 'label'])\n",
    "print(td_df.shape)\n",
    "td_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(td_df):\n",
    "    td_df = td_df.copy()\n",
    "    \n",
    "    td_df.loc[:, 'label'] = pd.to_numeric(td_df['label'], errors='coerce')\n",
    "    \n",
    "    td_df = td_df.dropna(subset=['label'])\n",
    "    \n",
    "    td_df.loc[:, 'query'] = td_df['query'].astype(str)\n",
    "    td_df.loc[:, 'answer'] = td_df['answer'].astype(str)\n",
    "    \n",
    "    train_df, temp_df = train_test_split(td_df, test_size=0.4, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "    \n",
    "    def create_dataset(df):\n",
    "        return [\n",
    "            {\n",
    "                'query': str(row['query']),\n",
    "                'answer': str(row['answer']),\n",
    "                'label': float(row['label'])\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "    \n",
    "    return {\n",
    "        'train': create_dataset(train_df),\n",
    "        'val': create_dataset(val_df),\n",
    "        'test': create_dataset(test_df)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(labels, preds):\n",
    "    metrics = {\n",
    "        'spearman_rho': spearmanr(labels, preds)[0],\n",
    "        'pearson_r': pearsonr(labels, preds)[0],\n",
    "\n",
    "        'mae': mean_absolute_error(labels, preds),\n",
    "        'r2': r2_score(labels, preds),\n",
    "        'mse': mean_squared_error(labels, preds),\n",
    "    }\n",
    "    \n",
    "    # Optional: Add threshold-based metrics if you have binary labels\n",
    "    if len(np.unique(labels)) == 2:  # Binary classification\n",
    "        metrics.update({\n",
    "            'accuracy': accuracy_score(labels, preds > 0.5),\n",
    "            'f1': f1_score(labels, preds > 0.5)\n",
    "        })\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ayoun\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayoungren94\u001b[0m (\u001b[33mayoungren-colostate\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "key_file = rf'D:\\Development\\cs580\\CSU-Industry-Skills\\WANDB_API_KEY.txt' \n",
    "\n",
    "with open(key_file, \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "MIN_DELTA = 0.005\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(config, datasets):\n",
    "    best_val_metric = -1 \n",
    "    patience = 0\n",
    "    best_state = None\n",
    "    arch_name = f\"lr_{config['lr']}_bs_{config['batch_size']}\"\n",
    "    wandb.init(\n",
    "        entity=\"ayoungren-colostate\",\n",
    "        project=\"sbert-param-search\",\n",
    "        name=arch_name,\n",
    "        config=config,\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SentenceTransformer(MODEL_NAME).to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    save_dir = \"saved_models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Starting Training for {arch_name}')\n",
    "\n",
    "    for epoch in range(1, 101):\n",
    "        print(f\"Beginning Epoch {epoch}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "        \n",
    "        random.shuffle(datasets['train'])\n",
    "        \n",
    "        for i in range(0, len(datasets['train']), config['batch_size']):\n",
    "            batch = datasets['train'][i:i+config['batch_size']]\n",
    "            \n",
    "            queries = [item['query'] for item in batch]\n",
    "            answers = [item['answer'] for item in batch]\n",
    "            labels = torch.tensor([item['label'] for item in batch], \n",
    "                                dtype=torch.float).to(device)\n",
    "\n",
    "            tokenizer = model.tokenizer\n",
    "            query_inputs = tokenizer(queries, padding=True, truncation=True, \n",
    "                                   return_tensors='pt').to(device)\n",
    "            answer_inputs = tokenizer(answers, padding=True, truncation=True,\n",
    "                                    return_tensors='pt').to(device)\n",
    "            \n",
    "            query_features = model(query_inputs)['sentence_embedding']\n",
    "            answer_features = model(answer_inputs)['sentence_embedding']\n",
    "\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(query_features, answer_features)\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(cos_sim, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            all_train_preds.extend(cos_sim.detach().cpu().numpy())\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(datasets['val']), 32):\n",
    "                batch = datasets['val'][i:i+32]\n",
    "                queries = [item['query'] for item in batch]\n",
    "                answers = [item['answer'] for item in batch]\n",
    "                labels = torch.tensor([item['label'] for item in batch], \n",
    "                                    dtype=torch.float).to(device)\n",
    "                \n",
    "                query_emb = model.encode(queries, convert_to_tensor=True, show_progress_bar=False)\n",
    "                answer_emb = model.encode(answers, convert_to_tensor=True, show_progress_bar=False)\n",
    "                cos_sim = torch.nn.functional.cosine_similarity(query_emb, answer_emb)\n",
    "                \n",
    "                val_preds.extend(cos_sim.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_metrics = compute_metrics(all_train_labels, all_train_preds)\n",
    "        val_metrics = compute_metrics(val_labels, val_preds)\n",
    "        \n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': epoch_loss / len(datasets['train']),\n",
    "            'train_mse': train_metrics['mse'],\n",
    "            'train_mae': train_metrics['mae'],\n",
    "            'train_r2': train_metrics['r2'],\n",
    "            'train_pearson_r': train_metrics['pearson_r'],\n",
    "            'train_spearman_rho': train_metrics['spearman_rho'],\n",
    "            'val_mse': val_metrics['mse'],\n",
    "            'val_mae': val_metrics['mae'],\n",
    "            'val_r2': val_metrics['r2'],\n",
    "            'val_pearson_r': val_metrics['pearson_r'],\n",
    "            'val_spearman_rho': val_metrics['spearman_rho'],\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "        if val_metrics['spearman_rho'] > best_val_metric + MIN_DELTA:\n",
    "            best_val_metric = val_metrics['spearman_rho']  # Track Spearman instead of Pearson\n",
    "            patience = 0\n",
    "            best_state = model.state_dict()\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': best_state,\n",
    "                'spearman_rho': best_val_metric,\n",
    "            }, os.path.join(save_dir, \"best_model.pth\"))\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    wandb.finish()\n",
    "    return best_val_metric, best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_211458-fwk3nveg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/fwk3nveg' target=\"_blank\">lr_2e-05_bs_16</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/fwk3nveg' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/fwk3nveg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_2e-05_bs_16\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Beginning Epoch 14\n",
      "Beginning Epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▇▇████████████</td></tr><tr><td>train_r2</td><td>▁▇▇████████████</td></tr><tr><td>train_spearman_rho</td><td>▁▆▇████████████</td></tr><tr><td>val_mae</td><td>██▅▄▃▄▃▄▂▂▁▁▁▂▅</td></tr><tr><td>val_mse</td><td>█▆▃▂▂▂▂▂▁▁▁▁▁▁▃</td></tr><tr><td>val_pearson_r</td><td>▁▆▇▇▇██████████</td></tr><tr><td>val_r2</td><td>▁▃▆▇▇▇▇▇██████▆</td></tr><tr><td>val_spearman_rho</td><td>▁▆▇▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_loss</td><td>2e-05</td></tr><tr><td>train_mae</td><td>0.01507</td></tr><tr><td>train_mse</td><td>0.00038</td></tr><tr><td>train_pearson_r</td><td>0.98054</td></tr><tr><td>train_r2</td><td>0.96086</td></tr><tr><td>train_spearman_rho</td><td>0.97859</td></tr><tr><td>val_mae</td><td>0.02954</td></tr><tr><td>val_mse</td><td>0.00111</td></tr><tr><td>val_pearson_r</td><td>0.98231</td></tr><tr><td>val_r2</td><td>0.87447</td></tr><tr><td>val_spearman_rho</td><td>0.98491</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_2e-05_bs_16</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/fwk3nveg' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/fwk3nveg</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_211458-fwk3nveg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_211658-uyibq9ja</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/uyibq9ja' target=\"_blank\">lr_3e-05_bs_16</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/uyibq9ja' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/uyibq9ja</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_3e-05_bs_16\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▇█████████</td></tr><tr><td>train_r2</td><td>▁▇█████████</td></tr><tr><td>train_spearman_rho</td><td>▁▇▇████████</td></tr><tr><td>val_mae</td><td>█▂▂▂▁▃▁▃▁▁▁</td></tr><tr><td>val_mse</td><td>█▂▁▂▁▂▁▂▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▇▇▇███████</td></tr><tr><td>val_r2</td><td>▁▇█▇█▇█▇███</td></tr><tr><td>val_spearman_rho</td><td>▁▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train_loss</td><td>3e-05</td></tr><tr><td>train_mae</td><td>0.01583</td></tr><tr><td>train_mse</td><td>0.00042</td></tr><tr><td>train_pearson_r</td><td>0.97835</td></tr><tr><td>train_r2</td><td>0.95713</td></tr><tr><td>train_spearman_rho</td><td>0.9745</td></tr><tr><td>val_mae</td><td>0.01428</td></tr><tr><td>val_mse</td><td>0.00043</td></tr><tr><td>val_pearson_r</td><td>0.97964</td></tr><tr><td>val_r2</td><td>0.95151</td></tr><tr><td>val_spearman_rho</td><td>0.98235</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_3e-05_bs_16</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/uyibq9ja' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/uyibq9ja</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_211658-uyibq9ja\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_211824-pgcnzsat</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/pgcnzsat' target=\"_blank\">lr_5e-05_bs_16</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/pgcnzsat' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/pgcnzsat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_5e-05_bs_16\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▇████████</td></tr><tr><td>train_r2</td><td>▁▇████████</td></tr><tr><td>train_spearman_rho</td><td>▁▇█▇██████</td></tr><tr><td>val_mae</td><td>█▄▃▄▃▁▄▁▁▁</td></tr><tr><td>val_mse</td><td>█▃▃▃▂▁▃▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▆▆▇▇▇▇███</td></tr><tr><td>val_r2</td><td>▁▆▆▆▇█▆███</td></tr><tr><td>val_spearman_rho</td><td>▁▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>5e-05</td></tr><tr><td>train_loss</td><td>2e-05</td></tr><tr><td>train_mae</td><td>0.01518</td></tr><tr><td>train_mse</td><td>0.00037</td></tr><tr><td>train_pearson_r</td><td>0.98083</td></tr><tr><td>train_r2</td><td>0.96172</td></tr><tr><td>train_spearman_rho</td><td>0.97737</td></tr><tr><td>val_mae</td><td>0.01336</td></tr><tr><td>val_mse</td><td>0.00039</td></tr><tr><td>val_pearson_r</td><td>0.98383</td></tr><tr><td>val_r2</td><td>0.95604</td></tr><tr><td>val_spearman_rho</td><td>0.986</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_5e-05_bs_16</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/pgcnzsat' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/pgcnzsat</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_211824-pgcnzsat\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_211943-ujr2vi46</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ujr2vi46' target=\"_blank\">lr_2e-05_bs_32</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ujr2vi46' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ujr2vi46</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_2e-05_bs_32\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Beginning Epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▆▇███████████</td></tr><tr><td>train_r2</td><td>▁▇▇███████████</td></tr><tr><td>train_spearman_rho</td><td>▁▆▇███████████</td></tr><tr><td>val_mae</td><td>█▅▅▃▃▂▃▃▃▂▁▁▁▃</td></tr><tr><td>val_mse</td><td>█▄▃▂▂▁▂▂▂▁▁▁▁▂</td></tr><tr><td>val_pearson_r</td><td>▁▅▇███████████</td></tr><tr><td>val_r2</td><td>▁▅▆▇▇█▇▇▇████▇</td></tr><tr><td>val_spearman_rho</td><td>▁▅▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_loss</td><td>2e-05</td></tr><tr><td>train_mae</td><td>0.01927</td></tr><tr><td>train_mse</td><td>0.0006</td></tr><tr><td>train_pearson_r</td><td>0.96943</td></tr><tr><td>train_r2</td><td>0.93815</td></tr><tr><td>train_spearman_rho</td><td>0.965</td></tr><tr><td>val_mae</td><td>0.02146</td></tr><tr><td>val_mse</td><td>0.00071</td></tr><tr><td>val_pearson_r</td><td>0.98027</td></tr><tr><td>val_r2</td><td>0.91971</td></tr><tr><td>val_spearman_rho</td><td>0.98253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_2e-05_bs_32</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ujr2vi46' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ujr2vi46</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_211943-ujr2vi46\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_212124-537mvda0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/537mvda0' target=\"_blank\">lr_3e-05_bs_32</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/537mvda0' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/537mvda0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_3e-05_bs_32\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▆▇██████</td></tr><tr><td>train_r2</td><td>▁▇███████</td></tr><tr><td>train_spearman_rho</td><td>▁▆███████</td></tr><tr><td>val_mae</td><td>█▂▂▂▂▂▁▁▁</td></tr><tr><td>val_mse</td><td>█▃▂▂▁▁▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▅▇██████</td></tr><tr><td>val_r2</td><td>▁▆▇▇█████</td></tr><tr><td>val_spearman_rho</td><td>▁▆▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train_loss</td><td>2e-05</td></tr><tr><td>train_mae</td><td>0.01994</td></tr><tr><td>train_mse</td><td>0.00067</td></tr><tr><td>train_pearson_r</td><td>0.96522</td></tr><tr><td>train_r2</td><td>0.93064</td></tr><tr><td>train_spearman_rho</td><td>0.96005</td></tr><tr><td>val_mae</td><td>0.01583</td></tr><tr><td>val_mse</td><td>0.00052</td></tr><tr><td>val_pearson_r</td><td>0.97755</td></tr><tr><td>val_r2</td><td>0.94144</td></tr><tr><td>val_spearman_rho</td><td>0.98048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_3e-05_bs_32</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/537mvda0' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/537mvda0</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_212124-537mvda0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_212231-ethv2lwf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ethv2lwf' target=\"_blank\">lr_5e-05_bs_32</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ethv2lwf' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ethv2lwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_5e-05_bs_32\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Beginning Epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▆▇███████████</td></tr><tr><td>train_r2</td><td>▁▇████████████</td></tr><tr><td>train_spearman_rho</td><td>▁▆▇███████████</td></tr><tr><td>val_mae</td><td>█▅▅▅▃▃▂▂▁▅▂▁▁▃</td></tr><tr><td>val_mse</td><td>█▄▃▃▂▂▁▁▁▂▁▁▁▂</td></tr><tr><td>val_pearson_r</td><td>▁▆▇███████████</td></tr><tr><td>val_r2</td><td>▁▅▆▆▇▇███▇███▇</td></tr><tr><td>val_spearman_rho</td><td>▁▆▇█▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>learning_rate</td><td>5e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.0163</td></tr><tr><td>train_mse</td><td>0.00044</td></tr><tr><td>train_pearson_r</td><td>0.97734</td></tr><tr><td>train_r2</td><td>0.95441</td></tr><tr><td>train_spearman_rho</td><td>0.97273</td></tr><tr><td>val_mae</td><td>0.01829</td></tr><tr><td>val_mse</td><td>0.00055</td></tr><tr><td>val_pearson_r</td><td>0.9837</td></tr><tr><td>val_r2</td><td>0.93781</td></tr><tr><td>val_spearman_rho</td><td>0.98554</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_5e-05_bs_32</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ethv2lwf' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/ethv2lwf</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_212231-ethv2lwf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_212412-49isgoje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/49isgoje' target=\"_blank\">lr_2e-05_bs_64</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/49isgoje' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/49isgoje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_2e-05_bs_64\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▅▇▇▇████████</td></tr><tr><td>train_r2</td><td>▁▇▇██████████</td></tr><tr><td>train_spearman_rho</td><td>▁▄▆▇▇████████</td></tr><tr><td>val_mae</td><td>█▅▄▂▂▂▂▂▁▃▁▁▁</td></tr><tr><td>val_mse</td><td>█▄▃▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▅▆▇▇████████</td></tr><tr><td>val_r2</td><td>▁▅▆▇▇▇███▇███</td></tr><tr><td>val_spearman_rho</td><td>▁▆▇▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.02196</td></tr><tr><td>train_mse</td><td>0.0008</td></tr><tr><td>train_pearson_r</td><td>0.95868</td></tr><tr><td>train_r2</td><td>0.91807</td></tr><tr><td>train_spearman_rho</td><td>0.95596</td></tr><tr><td>val_mae</td><td>0.01917</td></tr><tr><td>val_mse</td><td>0.00066</td></tr><tr><td>val_pearson_r</td><td>0.97827</td></tr><tr><td>val_r2</td><td>0.9252</td></tr><tr><td>val_spearman_rho</td><td>0.98158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_2e-05_bs_64</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/49isgoje' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/49isgoje</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_212412-49isgoje\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_212546-oo3s38a6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/oo3s38a6' target=\"_blank\">lr_3e-05_bs_64</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/oo3s38a6' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/oo3s38a6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_3e-05_bs_64\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▅▇▇████████</td></tr><tr><td>train_r2</td><td>▁▇▇█████████</td></tr><tr><td>train_spearman_rho</td><td>▁▅▇▇████████</td></tr><tr><td>val_mae</td><td>█▃▂▃▂▁▁▁▁▁▂▂</td></tr><tr><td>val_mse</td><td>█▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▅▆▇████████</td></tr><tr><td>val_r2</td><td>▁▆▇▇████████</td></tr><tr><td>val_spearman_rho</td><td>▁▅▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>12</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.02174</td></tr><tr><td>train_mse</td><td>0.00078</td></tr><tr><td>train_pearson_r</td><td>0.95946</td></tr><tr><td>train_r2</td><td>0.91932</td></tr><tr><td>train_spearman_rho</td><td>0.9552</td></tr><tr><td>val_mae</td><td>0.02488</td></tr><tr><td>val_mse</td><td>0.00093</td></tr><tr><td>val_pearson_r</td><td>0.9754</td></tr><tr><td>val_r2</td><td>0.89568</td></tr><tr><td>val_spearman_rho</td><td>0.97975</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_3e-05_bs_64</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/oo3s38a6' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/oo3s38a6</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_212546-oo3s38a6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_212715-t610tcj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/t610tcj3' target=\"_blank\">lr_5e-05_bs_64</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/t610tcj3' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/t610tcj3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_5e-05_bs_64\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▆▇▇██████</td></tr><tr><td>train_r2</td><td>▁▇████████</td></tr><tr><td>train_spearman_rho</td><td>▁▆▇▇██████</td></tr><tr><td>val_mae</td><td>█▅▅▂▂▂▁▂▁▄</td></tr><tr><td>val_mse</td><td>█▄▃▁▁▁▁▁▁▂</td></tr><tr><td>val_pearson_r</td><td>▁▅▇███████</td></tr><tr><td>val_r2</td><td>▁▅▆██████▇</td></tr><tr><td>val_spearman_rho</td><td>▁▅▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>5e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.01976</td></tr><tr><td>train_mse</td><td>0.00065</td></tr><tr><td>train_pearson_r</td><td>0.96699</td></tr><tr><td>train_r2</td><td>0.93273</td></tr><tr><td>train_spearman_rho</td><td>0.965</td></tr><tr><td>val_mae</td><td>0.02395</td></tr><tr><td>val_mse</td><td>0.00089</td></tr><tr><td>val_pearson_r</td><td>0.97688</td></tr><tr><td>val_r2</td><td>0.89936</td></tr><tr><td>val_spearman_rho</td><td>0.98006</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_5e-05_bs_64</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/t610tcj3' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/t610tcj3</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_212715-t610tcj3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_212828-7h7mhei1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/7h7mhei1' target=\"_blank\">lr_2e-05_bs_128</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/7h7mhei1' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/7h7mhei1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_2e-05_bs_128\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Beginning Epoch 14\n",
      "Beginning Epoch 15\n",
      "Beginning Epoch 16\n",
      "Beginning Epoch 17\n",
      "Beginning Epoch 18\n",
      "Beginning Epoch 19\n",
      "Beginning Epoch 20\n",
      "Beginning Epoch 21\n",
      "Beginning Epoch 22\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▃▅▆▇▇▇▇▇█████████████</td></tr><tr><td>train_r2</td><td>▁▆▇▇██████████████████</td></tr><tr><td>train_spearman_rho</td><td>▁▃▅▆▇▇▇▇██████████████</td></tr><tr><td>val_mae</td><td>█▅▄▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_mse</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▄▅▆▇▇▇▇██████████████</td></tr><tr><td>val_r2</td><td>▁▅▆▇▇▇▇███████████████</td></tr><tr><td>val_spearman_rho</td><td>▁▄▆▆▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.02149</td></tr><tr><td>train_mse</td><td>0.00077</td></tr><tr><td>train_pearson_r</td><td>0.96</td></tr><tr><td>train_r2</td><td>0.92082</td></tr><tr><td>train_spearman_rho</td><td>0.95362</td></tr><tr><td>val_mae</td><td>0.01821</td></tr><tr><td>val_mse</td><td>0.00061</td></tr><tr><td>val_pearson_r</td><td>0.97673</td></tr><tr><td>val_r2</td><td>0.93173</td></tr><tr><td>val_spearman_rho</td><td>0.97954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_2e-05_bs_128</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/7h7mhei1' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/7h7mhei1</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_212828-7h7mhei1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_213220-a2fe1hti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/a2fe1hti' target=\"_blank\">lr_3e-05_bs_128</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/a2fe1hti' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/a2fe1hti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_3e-05_bs_128\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Beginning Epoch 14\n",
      "Beginning Epoch 15\n",
      "Beginning Epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▄▆▇▇▇▇▇████████</td></tr><tr><td>train_r2</td><td>▁▇▇▇████████████</td></tr><tr><td>train_spearman_rho</td><td>▁▃▆▇▇▇██████████</td></tr><tr><td>val_mae</td><td>█▆▄▃▂▃▄▂▂▂▂▁▁▂▂▂</td></tr><tr><td>val_mse</td><td>█▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▅▆▇▇▇▇█████████</td></tr><tr><td>val_r2</td><td>▁▄▆▇▇▇▇▇████████</td></tr><tr><td>val_spearman_rho</td><td>▁▅▆▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.02134</td></tr><tr><td>train_mse</td><td>0.00078</td></tr><tr><td>train_pearson_r</td><td>0.95951</td></tr><tr><td>train_r2</td><td>0.9197</td></tr><tr><td>train_spearman_rho</td><td>0.95682</td></tr><tr><td>val_mae</td><td>0.02485</td></tr><tr><td>val_mse</td><td>0.00093</td></tr><tr><td>val_pearson_r</td><td>0.97746</td></tr><tr><td>val_r2</td><td>0.8951</td></tr><tr><td>val_spearman_rho</td><td>0.98089</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_3e-05_bs_128</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/a2fe1hti' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/a2fe1hti</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_213220-a2fe1hti\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_213535-qp805gax</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/qp805gax' target=\"_blank\">lr_5e-05_bs_128</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/qp805gax' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/qp805gax</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for lr_5e-05_bs_128\n",
      "Beginning Epoch 1\n",
      "Beginning Epoch 2\n",
      "Beginning Epoch 3\n",
      "Beginning Epoch 4\n",
      "Beginning Epoch 5\n",
      "Beginning Epoch 6\n",
      "Beginning Epoch 7\n",
      "Beginning Epoch 8\n",
      "Beginning Epoch 9\n",
      "Beginning Epoch 10\n",
      "Beginning Epoch 11\n",
      "Beginning Epoch 12\n",
      "Beginning Epoch 13\n",
      "Beginning Epoch 14\n",
      "Beginning Epoch 15\n",
      "Beginning Epoch 16\n",
      "Beginning Epoch 17\n",
      "Beginning Epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_pearson_r</td><td>▁▄▆▇▇▇████████████</td></tr><tr><td>train_r2</td><td>▁▇▇▇██████████████</td></tr><tr><td>train_spearman_rho</td><td>▁▄▆▇▇▇████████████</td></tr><tr><td>val_mae</td><td>█▇▃▆▅▄▂▂▂▃▄▃▂▂▁▁▁▃</td></tr><tr><td>val_mse</td><td>██▃▄▃▃▂▁▁▂▂▂▁▁▁▁▁▂</td></tr><tr><td>val_pearson_r</td><td>▁▄▆▆▇▇▇███████████</td></tr><tr><td>val_r2</td><td>▁▁▆▅▆▆▇██▇▇▇█████▇</td></tr><tr><td>val_spearman_rho</td><td>▁▅▆▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>18</td></tr><tr><td>learning_rate</td><td>5e-05</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.01883</td></tr><tr><td>train_mse</td><td>0.00062</td></tr><tr><td>train_pearson_r</td><td>0.9683</td></tr><tr><td>train_r2</td><td>0.93631</td></tr><tr><td>train_spearman_rho</td><td>0.96701</td></tr><tr><td>val_mae</td><td>0.02855</td></tr><tr><td>val_mse</td><td>0.00111</td></tr><tr><td>val_pearson_r</td><td>0.97969</td></tr><tr><td>val_r2</td><td>0.87502</td></tr><tr><td>val_spearman_rho</td><td>0.98277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_5e-05_bs_128</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/qp805gax' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/qp805gax</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_213535-qp805gax\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = prepare_datasets(td_df)\n",
    "    \n",
    "param_grid = ParameterGrid({\n",
    "    'lr': [2e-5, 3e-5, 5e-5],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'weight_decay': [0.01]\n",
    "})\n",
    "\n",
    "best_f1 = -1\n",
    "best_model = None\n",
    "best_config = None\n",
    "\n",
    "for config in param_grid:\n",
    "    val_f1, state_dict = train_and_evaluate(config, datasets)\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_model = state_dict\n",
    "        best_config = config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoun\\AppData\\Local\\Temp\\ipykernel_11648\\4132354858.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"saved_models/best_model.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 13 with Spearman ρ = 0.984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\cs580\\CSU-Industry-Skills\\bert-model\\wandb\\run-20250403_214555-x3dqi3cq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/x3dqi3cq' target=\"_blank\">Best Model Arch: lr--5e-05__bs--32</a></strong> to <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/x3dqi3cq' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/x3dqi3cq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: {'spearman_rho': np.float64(0.9881507906394621), 'pearson_r': np.float64(0.9869179341449975), 'mae': 0.01843222628654548, 'r2': 0.9440507836431647, 'mse': 0.0005618930258482958}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>test_pearson_r</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>test_spearman_rho</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_mae</td><td>0.01843</td></tr><tr><td>test_mse</td><td>0.00056</td></tr><tr><td>test_pearson_r</td><td>0.98692</td></tr><tr><td>test_r2</td><td>0.94405</td></tr><tr><td>test_spearman_rho</td><td>0.98815</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Best Model Arch: lr--5e-05__bs--32</strong> at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/x3dqi3cq' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search/runs/x3dqi3cq</a><br> View project at: <a href='https://wandb.ai/ayoungren-colostate/sbert-param-search' target=\"_blank\">https://wandb.ai/ayoungren-colostate/sbert-param-search</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250403_214555-x3dqi3cq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"saved_models/best_model.pth\")\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME) \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Loaded model from epoch {checkpoint['epoch']} with Spearman ρ = {checkpoint['spearman_rho']:.3f}\")\n",
    "\n",
    "if best_model:\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    test_loader = DataLoader(datasets['test'], batch_size=32)\n",
    "    test_preds, test_labels = [], []\n",
    "\n",
    "    wandb.init(\n",
    "        entity=\"ayoungren-colostate\",\n",
    "        project=\"sbert-param-search\",\n",
    "        name=f\"Best Model Arch: lr--{best_config['lr']}__bs--{best_config['batch_size']}\",\n",
    "        config=best_config,\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    model.eval()\n",
    "    test_preds, test_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            queries = batch['query']\n",
    "            answers = batch['answer']\n",
    "            labels = batch['label'].to(device)\n",
    "            query_emb = model.encode(queries, convert_to_tensor=True, show_progress_bar=False)\n",
    "            answer_emb = model.encode(answers, convert_to_tensor=True, show_progress_bar=False)\n",
    "            \n",
    "            cos_sim = torch.nn.functional.cosine_similarity(query_emb, answer_emb)\n",
    "            \n",
    "            test_preds.extend(cos_sim.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_metrics = compute_metrics(test_labels, test_preds)\n",
    "    print(\"Test Metrics:\", test_metrics)\n",
    "\n",
    "    wandb.log({\n",
    "        'test_mse': test_metrics['mse'],\n",
    "        'test_mae': test_metrics['mae'],\n",
    "        'test_r2': test_metrics['r2'],\n",
    "        'test_pearson_r': test_metrics['pearson_r'],\n",
    "        'test_spearman_rho': test_metrics['spearman_rho'],\n",
    "    })\n",
    "\n",
    "    wandb.finish()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoun\\AppData\\Local\\Temp\\ipykernel_11648\\984444441.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"saved_models/best_model.pth\")\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt given to the model with Sentence BERT Embeddings:\n",
      "What skills am I lacking for the following job position, given the classes I have taken?\n",
      "\n",
      "Job Title: Amazon_Graduate_Software_Engineer\n",
      " Job Description:  Do you want to solve business challenges through innovative technology? Do you enjoy working on cutting-edge, scalable services technology in a team environment? Do you like working on industry-defining projects that move the needle? At Amazon, we hire the best minds in technology to innovate and build on behalf of our customers. The intense focus we have on our customers is why we are one of the world's most beloved brands ? customer obsession is part of our company DNA. Our Software Development Engineers (SDEs) use cutting-edge technology to solve complex problems and get to see the impact of their work first-hand. If this is you, come chart your own path at Amazon! The challenges SDEs solve for at Amazon are big and impact millions of customers, sellers, and products around the world. We're looking for individuals who are excited by the idea of creating new products, features, and services from scratch while managing ambiguity and the pace of a company whose ship cycles are measured in weeks, not years. Key job responsibilities?- Collaborate with experienced cross-disciplinary Amazonians to conceive, design, and bring to market innovative products and services.?- Design and build innovative technologies in a large distributed computing environment and help lead fundamental changes in the industry.?- Create solutions to run predictions on distributed systems with exposure to innovative technologies at incredible scale and speed.?- Build distributed storage, index, and query systems that are scalable, fault-tolerant, low cost, and easy to manage/use.?- Work in an agile environment to deliver high quality software. BASIC QUALIFICATIONS - Graduated less than 24 months ago or about to complete a Bachelor's or Master's Degree in Computer Science, Computer Engineering, or related fields at time of application?- Although no specific programming language is required ? you should be familiar with the syntax of languages such as Java, C/C++, or Python?- Knowledge of Computer Science fundamentals such as object-oriented design, algorithm design, data structures, problem solving and complexity analysis. PREFERRED QUALIFICATIONS - Previous technical internship(s) if applicable?- Experience with distributed, multi-tiered systems, algorithms, and relational databases?- Experience in optimization mathematics such as linear programming and nonlinear optimisation?- Ability to effectively articulate technical challenges and solutions?- Adept at handling ambiguous or undefined problems as well as ability to think abstractly.\n",
      "\n",
      "COURSES TAKEN:\n",
      "\tCOURSE: CS314\n",
      "\t\tCS314 SKILLS: Agile, Black Box Testing, Burndown Charts, Clean Code, Cmmi, Code Climate, Code Quality, Communication, Compatability Standards, Concurrency, Configuration Management, Continuous Integration, Databases, Development Environments, Devops, Docker, Docker Container, Establishing Interpersonal Rela, Git, Github, Github Actions, Github Projects, Github Repository, Individual Metrics, Integration Tests, Intellij, Java, Java Concurrency, Java Spark, Json, Junit, Kml, Linux, Mariadb, Maven, Networking, Npm, Optimization, Peer Evaluation, Peer Review, Port Forwarding, Postman, Problem Solving, Product Integration, Project Management, Project Planning, Refactoring, Remote Development, Rest Api, Retrospectives, Scrum, Slack, Slf4J, Software Development Practices, Source Control, Sprint Planning, Sql, Story Boards, Story Sizing, Task Breakdown, Team Development Experience, Team Diversity, Team Metrics, Teamwork, Test Driven Development, Tuckman'S Model, Unix, Use Case Testing, Verification, VS Code, Webpack, White Box Testing\n",
      "\tCOURSE: CS165\n",
      "\t\tCS165 SKILLS: Algorithms, Assertions, B+ Trees, Binary Search Trees, Black Box Testing, Branching Recursion, Data Structures, Dequeues, Expression Trees, Generics, Graph, Hashmap, Infix, Inheritance, Java, Linkedlists, Object Oriented Principles, Object Oriented Programming, Pcre, Polymorphism, Postfix, Prefix, Priority Queues, Problem Solving, Queues, Regex, Stack, Unit Testing\n",
      "\tCOURSE: CS201\n",
      "\t\tCS201 SKILLS: Argument Construction, Computer Solution Designing, Computer Solution Implementatio, Computer Solution Operations, Decision Making, Ethical Dilemma Analysis, Ethical Dilemma Problem Solving, Ethics Analysis, Legal Obligations, Moral Obligations, Philosophy, Professional Code Of Ethics\n",
      "\tCOURSE: CS370\n",
      "\t\tCS370 SKILLS: Commercial Operating Systems, Containers, Deadlocks, Deadlocks Management, Design Threaded Programs, File System Architecture, Interprocess Communication, Kernel Threads, Memory Management, Open Source Operating Systems, Operating Systems, Process Synchronization, Processes Management, Resource Management, Scheduling Algorithms, Storage Architecture, Symmetric Multiprocessing, Synchronization, Task Synchronization, Thread Management, Threads, Type-1 Hypervisors, Type-2 Hypervisors, User Threads\n",
      "\tCOURSE: CS150\n",
      "\t\tCS150 SKILLS: Conditionals, Data Analysis, Data Visualization, Dictionaries, Functions, Hcc, Html, I O Console, I O File, Libraries, Lists, Loops, Operator, Privacy, Python, Research, Research Design, Security, Sets\n",
      "\tCOURSE: CS110\n",
      "\t\tCS110 SKILLS: Data Analysis, Data Manipulation, Data Visualization, Hardware, Privacy, Research, Security\n",
      "\tCOURSE: CS162\n",
      "\t\tCS162 SKILLS: Abstraction, Arrays, Assignment, Booleans, Characters, Classes, Conditionals, Encapsulations, Expressions, I O File, Inheritance, Interfaces, Java, Lists, Loops, Object Oriented Programming, Objects, Operator, Polymorphism, Recursion, Sorting, Strings\n",
      "\tCOURSE: CS270\n",
      "\t\tCS270 SKILLS: Activation Records, Arithmetic Logic Unit, Assembly, Bitwise Operators, C, C++, Circuits, Computer Architecture, Datatype Conversion, Digital Logic, Dynamic Memory Management, Gates, Global Variables, Instruction Set Architectures, Lc3, Logism, Memory Management, Number Formats, Point, Registers, Stack, State Machine, Subroutines, Transistors\n",
      "\tCOURSE: CS250\n",
      "\t\tCS250 SKILLS: Assembly, B+ Trees, Bits, Boolean Algebra, Boolean Logic, Border Gateway Protocol, Cache, Computer Architecture, Data Structures, Data Structures For Storage Sys, Databases, Datatypes, Distributed Systems, Domain Name System, File Systems, Frameworks, Graphic Processing Unit, Harvard Architectue, Internet Protocol, Logged Structure Merge, Logic Design, Machine Language, Main Memory, Memory Efficientcy, Memory Hierarchy, Memory Management, Nand Gates, Networks, Neuromorphic Computing, Numeric Datatypes, Parallel Systems, Parallelization, Processors, Registers, Signed Unsigned Numbers, Sorted Strings Tables, Storage, Transmission Control Protocol, User Datagram Protocol\n",
      "\tCOURSE: CS320\n",
      "\t\tCS320 SKILLS: Bipartite Graph, Breadth First, Depth First, Dictionaries, Divide & Conquer, Dynamic Multi-Threading, Dynamic Programming, Graph Algorithm, Greedy Algorithms, Greedy Proofs, Heaps, Heapsort, Knapsack, Line Of Sight Algorithm, Master Theorem, Memoization, Memory-Efficient Knapsack, Minimum Spanning Tree, Non-Deterministic Polynomial Cl, Non-Deterministic Polynomial Co, Orders Of Magnitude, Parallel Algorithms, Parallel Scans, Polynomial Class, Polynomial Time Reduction, Prefix Sums, Python, Recursive Substructure, Shortest Paths, Topological Sort, Tree Algorithm\n",
      "\tCOURSE: CS464\n",
      "\t\tCS464 SKILLS: Experimental Design, Human Centered Interaction Foun, Human Computer Interaction, Human Computer Interaction Rese, Human Factors, Hypothesis Testing, Interaction Design Principles, Latex, Perception, Principles Of User Experience, Principles Of User Usability, Prototyping, Publishing Research Paper, Qualitiative Analysis, Scientific Foundations, User Centered Interaction Desig, Writing Research Paper\n",
      "\tCOURSE: CS414\n",
      "\t\tCS414 SKILLS: Architechure Design, Backlogs Refinement, Code Idioms, Code Styles, Cohesion, Conceptual Modeling, Coupling, Crc Modeling, Design Modeling, Design Models, Design Patterns, Domain Modeling, Gather Requirements, Inheritance, Interfaces, Object Oriented Analysis, Object Oriented Design, Object Oriented Principles, Problem Analysis, Refactoring, Requirement Breakdown, Requirements Engineering, Retroactives, Software Engineering Ethics, Software Process Models, Story Mapping, Team Development Experience, Team Interaction, Team Project, Test Driven Development\n",
      "\tCOURSE: CS164\n",
      "\t\tCS164 SKILLS: 2D Arrays, Abstract Classes, Algorithms, Arraylists, Arrays, Branching, Classes, Code Comprehention, Code Design, Code Reading Analysis, Conditionals, Datatypes, Debugging, Exceptions, File Input, File Output, Git, Github, Ide, Intellij, Interfaces, Java, Java Development Environment, Javadoc, Linux, Logical Operators, Loops, Methods, Obects, Object Oriented Programming, Polymorphism, Problem Solving, Putty, Quality Assurance, Recursion, Searching, Sorting, Ssh, String Manipulation, Strings, Testing, Uml, Version Control, VS Code, Windows\n",
      "\tCOURSE: CS152\n",
      "\t\tCS152 SKILLS: Algorithms, Data Analysis, Data Visualization, Functions, I O File, Libraries, Logic, Problem Solving\n",
      "\tCOURSE: CS220\n",
      "\t\tCS220 SKILLS: Anaconda, Big O, Combinations, Counting, Directed Graphs, Functions, Graph, Induction Proof, Jupyter Notebook, Logical Inference, Loop Invariants, Mathematical Proof, Matplotlib, Miniconda, Permutations, Predicate Logic, Propositional Logic, Python, Relations, Sets\n",
      "\tCOURSE: CS430\n",
      "\t\tCS430 SKILLS: Application Development, Concurrency, Create, Manage, And Optimize Da, Creating Database, Data Modeling, Database Design, Database Guis, Database Recovery, Database Security, Database Systems, E R Diagram, Hash Table, Indexing, Locking, Migrating Databases, Mysql, Normalization, Queries, Query Processing, Relational Algebra, Robust Implementation Of Databa, Sql, Storage Management, Transaction Management, Transactions, Updating Databases\n",
      "\tCOURSE: CS214\n",
      "\t\tCS214 SKILLS: Agile, Artifact Management, Code Coverage, Coding Standards, Debugging, Documentation, Functional Programming, Git, Individual Software Development, Java, Junit Testing, Memory Efficientcy, Project Management, Project Planning, Refactoring, Software Design, Software Engineering Process, Software Implementation, Software Maintenance, Software Testing, Test Driven Development, Time Efficiency\n",
      "\tCOURSE: CS356\n",
      "\t\tCS356 SKILLS: Access Control, Buffer Overflow Attacks, Cryptographic Tools, Database Security, Defensive Programming Technique, Denial Of Service Attacks, Ethical Hacking Experiments, Hacking Demos, Internet Authentication, Intrusion Detection, Malicious Software, Prevention Systems, User Authentication\n",
      "\n",
      "Model Response:\n",
      "[{ \"size\": [{ \"x\": \"0\", \"y\": \"0\", \"z\": \"0\", \"1\": \"0\"), \"url\": \"https://d3dims.github.io/scala/blob/master/scala.js/scala.application/scala.application.js\", \"content\": \"/Users//danielkong/scala/src/application/scala.Application.scala\", \"vendor\": \"google\", \"distributor\": \"devel\", \"license\": [{ \"version\": \"1.0\" },{ \"version\": \"1.4\" }], \"source\": \"github.com\", \"tags\": [ { \"x\": \"0\", \"y\": \"0\", \"z\": \"0\" }, { \"x\": \"0\", \"y\": \"0\", \"z\": \"0\" } ] }]);\n",
      "\n",
      "[{\"type\": \"module\", \"moduleId\": \"scala-application-scala\", \"description\": \"This module provides an implementation of a Scala application with simple and fluent interfaces to JavaScript. If you add functions to this module in your tests, you will see a JavaScript object, called the scala object. The module provides the code the JavaScript is used to write the scala module: a scala.base.js script, passed with an initializer parameter called scala.application.js (which will be created in the app/app) along with an implementation of a JavaScript module that will execute the scala application. These scripts will be generated in the app directory and compiled into the test app. If you've just added a callback for the scala.js module to your tests, or if you've added one in the runtime and that one is used only after a test starts and a new test is run, this is a good time to add this to your project's source code. In most cases, you will want to call scala.application.scala.Callback in all your JS code and then make sure to create your callback. This is done through standard scala.core.extensions.Callback. The code from the scala.application.scala module can be included in a test run of your own, but you can extend it or call the scala.application.scala.Callback within your script, or it can be generated in another way to create a new test call.\n",
      "\n",
      "[{ \"module\": { \"moduleDef\": \"scala\" } }, { \"moduleName\": \"scala-application-scala\" }], \"moduleExtensions\": \"scala-application-scala.core.extensions\" }]}\n",
      "\n",
      "This module offers simple methods to access and write JavaScript modules from the scala.application.scala module. A scala.application.scala module may contain a number of methods in which you can use scala.application.scala.Callback or require a scala.application.scala module. These include:\n",
      "\n",
      "scala.base.js.\n",
      "\n",
      ". scala.application.js.\n",
      "\n",
      ". scala.module.js.\n",
      "\n",
      ". scala.module.js.\n",
      "\n",
      "This module defines JavaScript modules with simple interactions to JavaScript code, the scala.application.scala. The scala.application.scala module provides a set of test tests. Each test will run in an exact parallel fashion.\n",
      "\n",
      "[{ \"module\": { \"moduleName\": \"scala-application-scala\" } }, { \"moduleExtensions\": \"scala-application-scala.core.extensions\" }], \"moduleDef\": \"scala\" }], \"script\": [\"scala.application.scala.Callback: require scala.application.scala.Callback\");\n",
      "\n",
      "[{ \"module\": { \"moduleName\": \"scala-application-scala\" } }, { \"module: { \"moduleName\": \"scala-application-scala.core\" }], \"module: { \"moduleExtensions\": \"scala-application-scala.core.extensions\" }], \"script: [\"scala.application.scala.Callback: require scala.application.scala.Callback\");\n",
      "\n",
      "[{ \"module\": { \"moduleName\": \"scala-application-scala.core\" }}, { \"module: { \"moduleName\": \"scala-application-scala.core\" }], \"module: { \"moduleExtensions\": \"scala-application-scala.core.extensions\" }], \"script\": [\"scala.application.scala.Callback: require scala.application.scala.Callback\n",
      "\n",
      "Expected Response:\n",
      "You are missing the following skills required by the postion: Agile environment, Complexity analysis, Analytical skills, Data structures, Distributed systems, Scalability, Object-oriented design, Technical articulation, Collaboration, Designing and building innovative technologies, Problem Solving Skills, Leadership, Distributed storage, Relational databases, Algorithm design, Efficiency, Innovation, Creating solutions for distributed systems, Fault Tolerance, Customer engagement\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "checkpoint = torch.load(\"saved_models/best_model.pth\")\n",
    "model = SentenceTransformer(MODEL_NAME) \n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    embedding = model.encode(prompt)\n",
    "    \n",
    "    response = text_generator(\n",
    "        f\"Based on these embeddings: {embedding[:3]}...\\n\\nResponse:\",\n",
    "        max_length=1024,\n",
    "        do_sample=True\n",
    "    )[0]['generated_text']\n",
    "    \n",
    "    return response.split(\"Response:\")[-1].strip()\n",
    "\n",
    "random_row = td_df.sample(n=1)\n",
    "prompt = random_row['query'].iloc[0]\n",
    "expected_answer = random_row['answer'].iloc[0]\n",
    "model_response = generate_response(prompt)\n",
    "print()\n",
    "print(f\"Prompt given to the model with Sentence BERT Embeddings:\\n{prompt}\")\n",
    "print(f'Model Response:\\n{model_response}')\n",
    "print()\n",
    "print(f'Expected Response:\\n{expected_answer}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for _, row in td_df.iterrows():\n",
    "    training_data.append({\n",
    "        \"input\": row[\"query\"],\n",
    "        \"output\": row[\"answer\"]\n",
    "    })\n",
    "\n",
    "import json\n",
    "with open(\"ollama_training_data.jsonl\", \"w\") as f:\n",
    "    for item in training_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo 'FROM mistral  # or llama3\n",
    "!SYSTEM \"You identify missing skills between job descriptions and courses. Use the format: \\\"You are missing: [skills].\\\"\"\n",
    "!PARAMETER temperature 0.3' > Modelfile\n",
    "\n",
    "!ollama create missing_skills -f Modelfile\n",
    "!ollama train missing_skills -f ollama_training_data.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_response(job_desc, courses_taken):\n",
    "    prompt = f\"\"\"\n",
    "    {job_desc}\n",
    "    {courses_taken}\n",
    "    \n",
    "    What skills are missing for this job given these courses?\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model=\"missing_skills\",  # Your fine-tuned model\n",
    "        prompt=prompt\n",
    "    )\n",
    "    return response[\"response\"]\n",
    "\n",
    "\n",
    "job_desc = \"Seeks Python developer with Django and AWS experience.\"\n",
    "courses_taken = [\"Intro to Python\", \"Databases 101\"]\n",
    "print(generate_response(job_desc, courses_taken))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
